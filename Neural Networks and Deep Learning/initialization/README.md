In this notebook, you will

- Understand that different initialization methods and their impact on your model performance

- Implement zero initialization and and see it fails to "break symmetry",

- Recognize that random initialization "breaks symmetry" and yields more efficient models,

- Understand that you could use both random initialization and scaling to get even better training performance on your model.

Credit: Coursera deeplearning specialization by Andrew Ng. 
